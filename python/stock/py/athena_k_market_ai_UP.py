# -*- coding: utf-8 -*-
"""
ğŸ“˜ athena_k_market_ai.py (v1.2 - FinanceDataReader/yfinance ì•ˆì •í™”)
--------------------------------------------
âœ… í•œêµ­ ì£¼ì‹ ì‹œì¥ ë°ì´í„° ë¶„ì„ ë° íŒ¨í„´ ê°ì§€ ìŠ¤í¬ë¦½íŠ¸
âœ… [FIXED] FinanceDataReader.financials AttributeError í•´ê²° (ê¸°ë³¸ì  ë¶„ì„ ë¡œì§ ë³€ê²½)
âœ… [FIXED] yfinance ë‰´ìŠ¤ NoneType ì—ëŸ¬ í•´ê²° (íƒ€ì„ìŠ¤íƒ¬í”„ ì•ˆì „ ê²€ì‚¬ ì¶”ê°€)
âœ… ì´ˆê¸° ì•ˆì „ ê²€ì‚¬, ë³‘ë ¬ ì²˜ë¦¬, DART ê³µì‹œ/ì¬ë¬´/ë‰´ìŠ¤ ê¸°ë°˜ ì•…ì¬ í•„í„°ë§ ì™„ë¹„
âœ… K-Means í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì‹œì¥ êµ­ë©´(Market Regime) ì •ì˜
"""

import os
import sys
import json
import time
import logging
import argparse
import traceback
import socket 
from pathlib import Path
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
import io
import base64

# ==============================
# 1. ì´ˆê¸° ì•ˆì „ ê²€ì‚¬ ë° í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ==============================

def safe_print_json(data, status_code=1):
    """
    í‘œì¤€ ì¶œë ¥(stdout)ìœ¼ë¡œ JSONì„ ì•ˆì „í•˜ê²Œ ì¶œë ¥í•˜ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.
    (ë¹„ì •ìƒ ì¢…ë£Œ ì‹œ status_code=1, ì •ìƒ ì™„ë£Œ ì‹œ status_code=0)
    """
    sys.stdout.write(json.dumps(data, ensure_ascii=False, indent=2) + "\n")
    sys.stdout.flush()
    if status_code != 0:
        # ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ í”„ë¡œì„¸ìŠ¤ ì¦‰ì‹œ ì¢…ë£Œ
        sys.exit(status_code)

def check_internet_connection(host="8.8.8.8", port=53, timeout=3):
    """
    ì¸í„°ë„· ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ëŠ” í•¨ìˆ˜ (Google DNS ì„œë²„ ì‚¬ìš©).
    """
    try:
        socket.setdefaulttimeout(timeout)
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.connect((host, port))
        s.close()
        return True
    except Exception:
        return False

# ì¹˜ëª…ì  ì´ˆê¸° ê²€ì‚¬ 1: ì¸í„°ë„· ì—°ê²° í™•ì¸ ë° ì¦‰ì‹œ ì¢…ë£Œ
if not check_internet_connection():
    safe_print_json({
        "error": "CRITICAL_ERROR",
        "reason": "ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ ì ê²€í•´ì£¼ì„¸ìš”. (Google DNS ì—°ê²° ì‹¤íŒ¨)",
        "mode": "initial_check"
    })
# (safe_print_json ë‚´ë¶€ì—ì„œ sys.exit(1) í˜¸ì¶œë¨)


# ì¹˜ëª…ì  ì´ˆê¸° ê²€ì‚¬ 2: í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° ì¦‰ì‹œ ì¢…ë£Œ
try:
    import FinanceDataReader as fdr
    import pandas as pd
    import mplfinance as mpf
    import matplotlib.pyplot as plt
    import numpy as np
    from scipy.signal import find_peaks
    import yfinance as yf
    
    # ê³ ê¸‰ ë¶„ì„ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
    import ta # Technical Analysis Library
    from sklearn.preprocessing import StandardScaler
    from sklearn.cluster import KMeans
    
    # DART ê³µì‹œ í•„í„°ë§ (í™˜ê²½ ë³€ìˆ˜ í™•ì¸)
    DART_API_KEY = os.getenv("DART_API_KEY") 
    DART_AVAILABLE = bool(DART_API_KEY)
    if DART_AVAILABLE:
        try:
            from dart_fss import Dart
        except ImportError as e:
            DART_AVAILABLE = False
            logging.warning(f"DART_API_KEYê°€ ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ dart-fss ëª¨ë“ˆì´ ì—†ì–´ DART ê¸°ëŠ¥ ë¹„í™œì„±í™”. ({e.name})")

except ModuleNotFoundError as e:
    safe_print_json({
        "error": "CRITICAL_ERROR",
        "reason": f"í•„ìˆ˜ ëª¨ë“ˆ ëˆ„ë½: {e.name} ì„¤ì¹˜ í•„ìš” (pip install {e.name} scikit-learn ta)",
        "mode": "initial_check"
    })
# (safe_print_json ë‚´ë¶€ì—ì„œ sys.exit(1) í˜¸ì¶œë¨)


# ==============================
# 2. ê²½ë¡œ ë° ìƒìˆ˜ ì„¤ì •
# ==============================
# BASE_DIR: ìƒìœ„ 2ë‹¨ê³„ ê²½ë¡œ (ì˜ˆ: /MyBaseLinkV2/python)
BASE_DIR = Path(__file__).resolve().parents[2]
LOG_DIR = BASE_DIR / "log"
DATA_DIR = BASE_DIR / "data" / "stock_data"
LISTING_FILE = BASE_DIR / "data" / "stock_list" / "stock_listing.json"
LOG_FILE = LOG_DIR / "stock_analyzer_ultimate.log"

# ==============================
# 3. í™˜ê²½ ì´ˆê¸°í™” ë° ìœ í‹¸ë¦¬í‹°
# ==============================
def setup_env():
    """í™˜ê²½ ë””ë ‰í† ë¦¬ë¥¼ ì„¤ì •í•˜ê³  ë¡œê¹…ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    LISTING_FILE.parent.mkdir(parents=True, exist_ok=True)
    
    # ë¶„ì„ ì†ë„ë¥¼ ìœ„í•´ ë¡œê¹… ë ˆë²¨ì„ WARNINGìœ¼ë¡œ ì„¤ì •
    logging.basicConfig(
        level=logging.WARNING, 
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(LOG_FILE, encoding="utf-8", mode='a'),
            logging.StreamHandler(sys.stdout)
        ]
    )

def set_korean_font():
    """Matplotlib í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    global MPLFINANCE_FONT
    try:
        if sys.platform.startswith('win'): font_family = 'Malgun Gothic'
        elif sys.platform.startswith('darwin'): font_family = 'AppleGothic'
        else: font_family = 'NanumGothic'
        
        plt.rc('font', family=font_family)
        plt.rcParams['axes.unicode_minus'] = False
        MPLFINANCE_FONT = font_family
    except Exception: 
        MPLFINANCE_FONT = 'sans-serif'
        logging.warning("í•œê¸€ í°íŠ¸ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ í°íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

MPLFINANCE_FONT = 'sans-serif' 
set_korean_font()
setup_env() 

def load_listing():
    """ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not LISTING_FILE.exists(): 
        logging.error(f"ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì—†ìŒ: {LISTING_FILE} -> ê¸°ë³¸ ì¢…ëª©(ì‚¼ì„±ì „ì)ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        # DartCorpCodeëŠ” ì‚¼ì„±ì „ì (005930)ì˜ ê³ ìœ  ë²ˆí˜¸ì…ë‹ˆë‹¤.
        return [{"Code": "005930", "Name": "ì‚¼ì„±ì „ì", "DartCorpCode": "00126380"}] 
    try:
        # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë¡œë“œ
        with open(LISTING_FILE, "r", encoding="utf-8") as f: 
            return json.load(f)
    except Exception as e:
        logging.error(f"ì¢…ëª© ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e} -> ê¸°ë³¸ ì¢…ëª©(ì‚¼ì„±ì „ì)ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        return [{"Code": "005930", "Name": "ì‚¼ì„±ì „ì", "DartCorpCode": "00126380"}]

def get_stock_name(symbol):
    """ì¢…ëª© ì½”ë“œë¡œ ì´ë¦„ì„ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        items = load_listing()
        for item in items:
            code = item.get("Code") or item.get("code")
            if code == symbol: return item.get("Name") or item.get("name")
        return symbol
    except Exception: return symbol

def get_dart_corp_code(symbol):
    """ì¢…ëª© ì½”ë“œë¡œ DART ê³ ìœ  ë²ˆí˜¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        items = load_listing()
        for item in items:
            code = item.get("Code") or item.get("code")
            if code == symbol: return item.get("DartCorpCode")
        return None
    except Exception: return None

# ==============================
# 4. ê³ ê¸‰ íŠ¹ì§• ê³µí•™ ë° í´ëŸ¬ìŠ¤í„°ë§ ë¡œì§
# ==============================

def calculate_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
    """ê³ ê¸‰ íŒ¨í„´ ì¸ì‹ì„ ìœ„í•´ ê¸°ìˆ ì  ì§€í‘œë¥¼ íŠ¹ì§•(Feature)ìœ¼ë¡œ ì¶”ê°€í•©ë‹ˆë‹¤."""
    df['RSI'] = ta.momentum.RSIIndicator(close=df['Close'], window=14, fillna=False).rsi()
    df['MACD'] = ta.trend.MACD(close=df['Close'], fillna=False).macd()
    
    bollinger = ta.volatility.BollingerBands(close=df['Close'], window=20, window_dev=2, fillna=False)
    df['BB_High'] = bollinger.bollinger_hband_indicator()
    df['BB_Width'] = bollinger.bollinger_wband()
    
    df['SMA_20'] = ta.trend.SMAIndicator(close=df['Close'], window=20, fillna=False).sma_indicator()
    df['SMA_50'] = ta.trend.SMAIndicator(close=df['Close'], window=50, fillna=False).sma_indicator()
    df['SMA_200'] = ta.trend.SMAIndicator(close=df['Close'], window=200, fillna=False).sma_indicator()
    
    df['TREND_CROSS'] = (df['SMA_20'] > df['SMA_50']).astype(int)
    
    df = df.dropna()
    return df

def add_market_regime_clustering(df: pd.DataFrame, n_clusters=4) -> pd.DataFrame:
    """ê¸°ìˆ ì  íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•˜ì—¬ ì‹œì¥ êµ­ë©´ì„ ì •ì˜í•©ë‹ˆë‹¤."""
    feature_cols = ['RSI', 'MACD', 'BB_Width', 'TREND_CROSS']
    min_data_length = 50 
    
    if len(df) < min_data_length or not all(col in df.columns for col in feature_cols):
        logging.warning(f"í´ëŸ¬ìŠ¤í„°ë§ì— í•„ìš”í•œ ë°ì´í„° ê¸¸ì´ê°€ {min_data_length}ì¼ ë¯¸ë§Œì…ë‹ˆë‹¤. ({len(df)}ì¼)")
        df['MarketRegime'] = -1 # ë°ì´í„° ë¶€ì¡± ì‹œ -1ë¡œ í‘œì‹œ
        return df

    data = df[feature_cols].copy()
    
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(data)
    
    # K-Means í´ëŸ¬ìŠ¤í„°ë§ 
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    df['MarketRegime'] = kmeans.fit_predict(scaled_data)
    
    return df


# ==============================
# 5. ê¸°ìˆ ì  ë¶„ì„ íŒ¨í„´ ë¡œì§ 
# ==============================

def find_peaks_and_troughs(df, prominence=0.01, width=3):
    """ì£¼ìš” ë´‰ìš°ë¦¬ì™€ ê³¨ì§œê¸° ì¸ë±ìŠ¤ ì°¾ê¸° (ìµœê·¼ 250ì¼ ê¸°ì¤€)"""
    recent_df = df.iloc[-250:].copy()
    if recent_df.empty: return np.array([]), np.array([])
    
    # ê°€ê²© ë³€ë™ì„±(í‘œì¤€í¸ì°¨)ì„ ê¸°ì¤€ìœ¼ë¡œ ë´‰ìš°ë¦¬/ê³¨ì§œê¸° ì¤‘ìš”ë„ ì„¤ì •
    std_dev = recent_df['Close'].std()
    peaks, _ = find_peaks(recent_df['Close'], prominence=std_dev * prominence, width=width)
    troughs, _ = find_peaks(-recent_df['Close'], prominence=std_dev * prominence, width=width)
    
    # ì „ì²´ ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    start_idx = len(df) - len(recent_df)
    return peaks + start_idx, troughs + start_idx

def find_double_bottom(df, troughs, tolerance=0.05, min_duration=30):
    """ì´ì¤‘ ë°”ë‹¥ íŒ¨í„´ ê°ì§€"""
    # ìµœê·¼ 250ì¼ ë‚´ì˜ ê³¨ì§œê¸°ë§Œ ì‚¬ìš©
    recent_troughs = [t for t in troughs if t >= len(df) - 250]
    if len(recent_troughs) < 2: return False, None, None, None
    
    idx2, idx1 = recent_troughs[-1], recent_troughs[-2] 
    price1, price2 = df['Close'].iloc[idx1], df['Close'].iloc[idx2]
    
    if idx2 - idx1 < min_duration: return False, None, None, None # ìµœì†Œ ê¸°ê°„ ì¶©ì¡±
    
    # ë°”ë‹¥ ê°€ê²©ì´ í—ˆìš© ì˜¤ì°¨ ë‚´ì¸ì§€ í™•ì¸
    is_price_matching = abs(price1 - price2) / min(price1, price2) < tolerance
    if not is_price_matching: return False, None, None, None
    
    interim_high = df['Close'].iloc[idx1:idx2].max() # ì¤‘ê°„ ë´‰ìš°ë¦¬
    current_price = df['Close'].iloc[-1]

    is_breakout = current_price > interim_high # ë„¥ ë¼ì¸ ëŒíŒŒ
    
    if is_breakout: return True, interim_high, 'Breakout', interim_high
    
    # ì ì¬ì  íŒ¨í„´ í™•ì¸ (ë°”ë‹¥ì—ì„œ 50% ì´ìƒ íšŒë³µ)
    retrace_ratio = (current_price - min(price1, price2)) / (interim_high - min(price1, price2)) if interim_high > min(price1, price2) else 0
    is_potential = retrace_ratio > 0.5 and current_price < interim_high 
    
    if is_potential: return False, interim_high, 'Potential', interim_high
        
    return False, None, None, None

def find_triple_bottom(df, troughs, tolerance=0.05, min_duration_total=75):
    """ì‚¼ì¤‘ ë°”ë‹¥ íŒ¨í„´ ê°ì§€"""
    recent_troughs = [t for t in troughs if t >= len(df) - 250]
    if len(recent_troughs) < 3: return False, None, None, None
    
    idx3, idx2, idx1 = recent_troughs[-1], recent_troughs[-2], recent_troughs[-3]
    price1, price2, price3 = df['Close'].iloc[idx1], df['Close'].iloc[idx2], df['Close'].iloc[idx3]
    
    if idx3 - idx1 < min_duration_total: return False, None, None, None # ìµœì†Œ ê¸°ê°„ ì¶©ì¡±
    
    # ì„¸ ë°”ë‹¥ ê°€ê²©ì´ í—ˆìš© ì˜¤ì°¨ ë‚´ì¸ì§€ í™•ì¸
    min_price = min(price1, price2, price3)
    max_price = max(price1, price2, price3)
    is_price_matching = (max_price - min_price) / min_price < tolerance
    if not is_price_matching: return False, None, None, None
    
    high1 = df['Close'].iloc[idx1:idx2].max()
    high2 = df['Close'].iloc[idx2:idx3].max()
    neckline = max(high1, high2) # ë„¥ ë¼ì¸ = ì¤‘ê°„ ë´‰ìš°ë¦¬ ì¤‘ ê°€ì¥ ë†’ì€ ê°’
    current_price = df['Close'].iloc[-1]

    is_breakout = current_price > neckline # ë„¥ ë¼ì¸ ëŒíŒŒ
    
    if is_breakout: return True, neckline, 'Breakout', neckline
    
    # ì ì¬ì  íŒ¨í„´ í™•ì¸
    retrace_ratio = (current_price - min_price) / (neckline - min_price) if neckline > min_price else 0
    is_potential = retrace_ratio > 0.5 and current_price < neckline
    
    if is_potential: return False, neckline, 'Potential', neckline
        
    return False, None, None, None


def find_cup_and_handle(df, peaks, troughs, handle_drop_ratio=0.3):
    """ì»µ ì•¤ í•¸ë“¤ íŒ¨í„´ ê°ì§€"""
    recent_peaks = [p for p in peaks if p >= len(df) - 250]
    if len(recent_peaks) < 2: return False, None, None, None
    
    peak_right_idx = recent_peaks[-1]
    peak_right_price = df['Close'].iloc[peak_right_idx]
    
    # ì»µ ëª¨ì–‘ í˜•ì„± í™•ì¸ ë¡œì§ (ê°„ë‹¨í™”)
    # ì»µì˜ ì˜¤ë¥¸ìª½ ë´‰ìš°ë¦¬ê°€ ê°€ì¥ ìµœê·¼ ë´‰ìš°ë¦¬ì—¬ì•¼ í•¨
    
    handle_start_idx = peak_right_idx 
    handle_max_drop = peak_right_price * (1 - handle_drop_ratio) # í•¸ë“¤ ìµœëŒ€ í•˜ë½ ê¹Šì´

    current_price = df['Close'].iloc[-1]
    
    # í•¸ë“¤ í˜•ì„± ì¡°ê±´: ì˜¤ë¥¸ìª½ ë´‰ìš°ë¦¬ ì´í›„ ê°€ê²©ì´ ê·¸ ë´‰ìš°ë¦¬ë¥¼ ë„˜ì§€ ì•Šê³ , ìµœëŒ€ í•˜ë½ í­(30%) ì´ë‚´ì— ìˆì–´ì•¼ í•¨
    is_handle_forming = (df['Close'].iloc[handle_start_idx:].max() <= peak_right_price) 
    is_handle_forming &= (current_price > handle_max_drop)

    if is_handle_forming and current_price > peak_right_price:
        return True, peak_right_price, 'Breakout', peak_right_price
    
    if is_handle_forming and current_price <= peak_right_price:
        return False, peak_right_price, 'Potential', peak_right_price
        
    return False, None, None, None

# ==============================
# 6. ê¸°ë³¸ì  ë¶„ì„ ë° ì•…ì¬ í•„í„°ë§ ë¡œì§
# ==============================

def get_basic_fundamentals(code):
    """yfinanceë¥¼ ì´ìš©í•´ ê¸°ë³¸ì ì¸ í€ë”ë©˜í„¸ ì§€í‘œ (P/E, P/B)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    FinanceDataReader.financials ì—ëŸ¬ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì´ í•¨ìˆ˜ë¡œ ëŒ€ì²´ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    fundamentals = {}
    try:
        # í•œêµ­ ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ì¢…ëª©ì€ .KSë¥¼ ë¶™ì—¬ì•¼ í•¨
        yf_ticker = f"{code}.KS" if not code.endswith('.KS') else code
        ticker = yf.Ticker(yf_ticker)
        info = ticker.info
        
        # P/E (Trailing PE)
        if 'trailingPE' in info and info['trailingPE'] is not None:
             fundamentals['PE_Ratio'] = info['trailingPE']
        
        # P/B (Price to Book)
        if 'priceToBook' in info and info['priceToBook'] is not None:
             fundamentals['PB_Ratio'] = info['priceToBook']

    except Exception as e:
        logging.warning(f"yfinance í€ë”ë©˜í„¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ({code}): {e}")
        
    return fundamentals

def get_yfinance_news(code):
    """yfinanceë¥¼ ì´ìš©í•´ ìµœê·¼ ë‰´ìŠ¤ í—¤ë“œë¼ì¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    headlines = []
    try:
        # í•œêµ­ ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ì¢…ëª©ì€ .KSë¥¼ ë¶™ì—¬ì•¼ í•¨
        yf_ticker = f"{code}.KS" if not code.endswith('.KS') else code
        ticker = yf.Ticker(yf_ticker)
        news_list = ticker.news
        filtered_headlines = []
        two_months_ago = datetime.now() - timedelta(days=60)
        
        for news in news_list:
            publish_timestamp = news.get('providerPublishTime')
            
            # NoneType ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ 'providerPublishTime'ì´ ì¡´ì¬í•˜ëŠ”ì§€ ì•ˆì „í•˜ê²Œ í™•ì¸
            if publish_timestamp is None:
                continue

            publish_date = datetime.fromtimestamp(publish_timestamp) 
            if publish_date >= two_months_ago:
                filtered_headlines.append({"title": news.get('title'), "link": news.get('link')})
            if len(filtered_headlines) >= 3: break # ìµœëŒ€ 3ê°œ í—¤ë“œë¼ì¸ë§Œ ê°€ì ¸ì˜´
        return filtered_headlines
    except Exception as e:
        # yfinanceì˜ ë¶ˆì•ˆì •ì„±(ì˜ˆ: API ë³€ê²½)ìœ¼ë¡œ ì¸í•œ ì—ëŸ¬ëŠ” ê²½ê³ ë¡œ ì²˜ë¦¬
        logging.warning(f"yfinance ë‰´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨ ({code}): {e}")
        return []

def get_fundamental_data(code):
    """ê¸°ë³¸ì  ë¶„ì„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    # FDR ëŒ€ì‹  yfinance ê¸°ë°˜ì˜ ê¸°ë³¸ í€ë”ë©˜í„¸ ì‚¬ìš©
    fundamentals = get_basic_fundamentals(code) 
    headlines = get_yfinance_news(code)
    return fundamentals, headlines

def check_for_negative_dart_disclosures(corp_code):
    """DART ê³µì‹œì—ì„œ ì•…ì¬ì„± í‚¤ì›Œë“œ ê²€ì‚¬ (í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©)"""
    if not DART_AVAILABLE or not corp_code or not DART_API_KEY: return False, None
    try:
        dart = Dart(DART_API_KEY)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=60) # ìµœê·¼ 60ì¼ ê³µì‹œ
        reports = dart.search(corp_code=corp_code, start_dt=start_date.strftime('%Y%m%d'))
        
        # ì•…ì¬ì„± í‚¤ì›Œë“œ ëª©ë¡
        negative_keywords = ["íš¡ë ¹", "ë°°ì„", "ì†Œì†¡ ì œê¸°", "ì†í•´ë°°ìƒ", "ê±°ë˜ì •ì§€", "ìƒì¥íì§€", "ê°ì‚¬ì˜ê²¬ ê±°ì ˆ", "íŒŒì‚°", "íšŒìƒ"]
        for report in reports:
            # ìœ ìƒì¦ì ì¤‘ ì œ3ìë°°ì •ì€ ê¸ì •ì ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•…ì¬ í•„í„°ì—ì„œ ì œì™¸
            if "ìœ ìƒì¦ì ê²°ì •" in report.report_nm and "ì œ3ìë°°ì •" in report.report_nm: continue 
            if any(keyword in report.report_nm for keyword in negative_keywords):
                return True, f"DART ê³µì‹œ ì•…ì¬: '{report.report_nm}'"
        return False, None
    except Exception as e:
        logging.error(f"DART ê³µì‹œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ({corp_code}): {e}")
        return False, None

def check_for_negatives(fundamentals, headlines, code, corp_code):
    """ë‰´ìŠ¤/ì¬ë¬´/ê³µì‹œ ê¸°ë°˜ìœ¼ë¡œ ì•…ì¬ì„± ì¢…ëª© ì—¬ë¶€ë¥¼ ê²€ì‚¬"""
    negative_keywords_news = ["íš¡ë ¹", "ë°°ì„", "ì†Œì†¡", "ë¶„ìŸ", "ê±°ë˜ ì •ì§€", "ì•…ì¬", "í•˜ë½ ì „ë§", "íˆ¬ìì£¼ì˜", "ì ì"]
    
    # 1. ë‰´ìŠ¤ ì•…ì¬ í™•ì¸
    for news in headlines:
        if any(keyword in news.get('title', '') for keyword in negative_keywords_news):
            return True, f"ë‰´ìŠ¤ ì•…ì¬: '{news.get('title')}'"
            
    # 2. ì¬ë¬´ ì•…ì¬ í™•ì¸ (yfinance ê¸°ë°˜ P/E, P/B ì‚¬ìš©)
    pe_ratio = fundamentals.get('PE_Ratio')
    pb_ratio = fundamentals.get('PB_Ratio')
    
    # P/E ë¹„ìœ¨ì´ ë§ˆì´ë„ˆìŠ¤ (ì ì)ì¸ ê²½ìš° ì•…ì¬ë¡œ íŒë‹¨
    if pe_ratio is not None and not pd.isna(pe_ratio) and pe_ratio < 0: 
        return True, f"ì¬ë¬´ ì•…ì¬: P/E {pe_ratio:.1f} (ì ì)"
    
    # P/B ë¹„ìœ¨ì´ 1.0 ë¯¸ë§Œ (ì¥ë¶€ê°€ì¹˜ë³´ë‹¤ ë‚®ìŒ)ì´ë”ë¼ë„ ë‹¤ë¥¸ í•„í„°ë¡œ ì¡ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 
    # ì—¬ê¸°ì„œëŠ” ê·¹ë„ë¡œ ë‚®ì€ ë°¸ë¥˜ì—ì´ì…˜ë§Œ í™•ì¸ (ì˜ˆ: 0.3 ë¯¸ë§Œ ë“±) - ë‹¨ë… ì•…ì¬ë¡œ ë³´ê¸° ì–´ë ¤ì›Œ ì¼ë‹¨ P/Eë§Œ ì‚¬ìš©

    # 3. DART ê³µì‹œ ì•…ì¬ í™•ì¸
    is_negative_dart, reason_dart = check_for_negative_dart_disclosures(corp_code)
    if is_negative_dart: return True, reason_dart
        
    return False, None

# ==============================
# 7. ë¶„ì„ ì‹¤í–‰ ë° í•„í„°ë§
# ==============================

def check_ma_conditions(df, periods, analyze_patterns):
    """ì´ë™ í‰ê· ì„  ë° íŒ¨í„´ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    results = {}
    
    ma_cols = {20: 'SMA_20', 50: 'SMA_50', 200: 'SMA_200'}

    # 200ì¼ ë¯¸ë§Œ ë°ì´í„°ëŠ” íŒ¨í„´ ë¶„ì„ì— ë¶€ì í•©í•˜ë‹¤ê³  íŒë‹¨
    if len(df) < 200: analyze_patterns = False
        
    # í˜„ì¬ê°€ vs ì´ë™ í‰ê· ì„  ë¹„êµ
    for p in periods:
        col_name = ma_cols.get(p)
        if col_name and col_name in df.columns:
            results[f"above_ma{p}"] = df['Close'].iloc[-1] > df[col_name].iloc[-1]
        elif len(df) >= p:
             # ì„ì‹œë¡œ MA ê³„ì‚° (analyze_symbolì—ì„œ ì´ë¯¸ ê³„ì‚°ë˜ì—ˆì„ ê°€ëŠ¥ì„± ë†’ìŒ)
             df[f'ma{p}'] = df['Close'].rolling(window=p, min_periods=1).mean() 
             results[f"above_ma{p}"] = df['Close'].iloc[-1] > df[f'ma{p}'].iloc[-1]
    
    # ê³¨ë“ /ë°ë“œ í¬ë¡œìŠ¤ ë¡œì§ (SMA_50 vs SMA_200)
    ma50_col = ma_cols.get(50)
    ma200_col = ma_cols.get(200)

    if ma50_col in df.columns and ma200_col in df.columns and len(df) >= 200:
        # ì „ë‚ ê³¼ ì˜¤ëŠ˜ ì´ë™í‰ê· ì„  ìœ„ì¹˜ ë¹„êµ
        ma50_prev, ma50_curr = df[ma50_col].iloc[-2], df[ma50_col].iloc[-1]
        ma200_prev, ma200_curr = df[ma200_col].iloc[-2], df[ma200_col].iloc[-1]

        # ê³¨ë“  í¬ë¡œìŠ¤: 50ì¼ì„ ì´ 200ì¼ì„  ì•„ë˜ì—ì„œ ìœ„ë¡œ êµì°¨
        results["goldencross_50_200_detected"] = (ma50_prev < ma200_prev and ma50_curr > ma200_curr)
        # ë°ë“œ í¬ë¡œìŠ¤: 50ì¼ì„ ì´ 200ì¼ì„  ìœ„ì—ì„œ ì•„ë˜ë¡œ êµì°¨
        results["deadcross_50_200_detected"] = (ma50_prev > ma200_prev and ma50_curr < ma200_curr)
    else:
        results["goldencross_50_200_detected"] = False
        results["deadcross_50_200_detected"] = False
    
    # íŒ¨í„´ ë¶„ì„ í™œì„±í™” ì‹œ
    if analyze_patterns:
        peaks, troughs = find_peaks_and_troughs(df)
        _, _, db_status, db_price = find_double_bottom(df, troughs)
        _, _, tb_status, tb_price = find_triple_bottom(df, troughs)
        _, _, ch_status, ch_price = find_cup_and_handle(df, peaks, troughs)
        
        results['pattern_double_bottom_status'] = db_status
        results['db_neckline_price'] = db_price

        results['pattern_triple_bottom_status'] = tb_status
        results['tb_neckline_price'] = tb_price

        results['pattern_cup_and_handle_status'] = ch_status
        results['ch_neckline_price'] = ch_price
        
    if 'MarketRegime' in df.columns:
        # K-Means í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ëŠ” ì •ìˆ˜í˜•ìœ¼ë¡œ ì €ì¥
        results['market_regime'] = int(df['MarketRegime'].iloc[-1])

    return results

def analyze_symbol(item, periods, analyze_patterns, exclude_negatives, pattern_type_filter):
    """ë‹¨ì¼ ì¢…ëª©ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    code = item.get("Code") or item.get("code")
    name = item.get("Name") or item.get("name")
    corp_code = item.get("DartCorpCode")
    path = DATA_DIR / f"{code}.parquet"
    
    # 1. ë°ì´í„° ë¡œë“œ ë° ìœ íš¨ì„± ê²€ì‚¬
    if not path.exists(): 
        logging.debug(f"[{code}] ë°ì´í„° íŒŒì¼ ì—†ìŒ.")
        return None
    
    try:
        df_raw = pd.read_parquet(path)
        if df_raw.empty or len(df_raw) < 50: 
            logging.debug(f"[{code}] ë°ì´í„° ë¶€ì¡± ({len(df_raw)}ì¼).")
            return None
        
        # 2. ë¶„ì„ì— ì‚¬ìš©í•  ìµœê·¼ 250ì¼ ë°ì´í„° ìŠ¬ë¼ì´ìŠ¤
        df = df_raw.iloc[-250:].copy()

        # 3. ê¸°ìˆ ì  íŠ¹ì§• ê³µí•™ ë° í´ëŸ¬ìŠ¤í„°ë§
        df = calculate_advanced_features(df)
        if len(df) < 50: return None
        
        df = add_market_regime_clustering(df)
        
        # 4. ê¸°ë³¸ì  ë¶„ì„ ë° ë‰´ìŠ¤ ìˆ˜ì§‘
        fundamentals, headlines = get_fundamental_data(code)
        
        # 5. ì•…ì¬ í•„í„°ë§
        if exclude_negatives:
            is_negative, reason = check_for_negatives(fundamentals, headlines, code, corp_code)
            if is_negative:
                logging.info(f"[{code}] {name}: ì•…ì¬ì„± ìš”ì¸ìœ¼ë¡œ ì œì™¸ë¨ - {reason}")
                return None
            
        # 6. ê¸°ìˆ ì  ì¡°ê±´ ë° íŒ¨í„´ ë¶„ì„
        analysis_results = check_ma_conditions(df, periods, analyze_patterns) 
        
        # 7. í•„í„° ìœ í˜•ì— ë”°ë¥¸ ìµœì¢… ë§¤ì¹­ ê²€ì‚¬
        is_match = True
        if pattern_type_filter:
            if pattern_type_filter == 'goldencross': 
                is_match = analysis_results.get("goldencross_50_200_detected", False)
            elif pattern_type_filter in ['double_bottom', 'triple_bottom', 'cup_and_handle']: 
                status_key = f'pattern_{pattern_type_filter}_status'
                status = analysis_results.get(status_key)
                # ëŒíŒŒ ë˜ëŠ” ì ì¬ì  íŒ¨í„´ ëª¨ë‘ ë§¤ì¹­ìœ¼ë¡œ ê°„ì£¼
                is_match = status in ['Breakout', 'Potential'] 
            elif pattern_type_filter.startswith('regime:'):
                if 'market_regime' in analysis_results:
                    try:
                        target_regime = int(pattern_type_filter.split(':')[1])
                        current_regime = analysis_results['market_regime']
                        is_match = (current_regime == target_regime)
                    except ValueError:
                        is_match = False
                else:
                    is_match = False
            elif pattern_type_filter == 'ma':
                 # MA í•„í„°ê°€ ëª…ì‹œì ìœ¼ë¡œ ìš”ì²­ë˜ì—ˆì„ ê²½ìš°, ëª¨ë“  MA ì¡°ê±´ì´ ì¶©ì¡±ë˜ì–´ì•¼ í•¨
                 is_match = all(analysis_results.get(f"above_ma{p}", False) for p in periods)
            else: 
                is_match = False # ì•Œ ìˆ˜ ì—†ëŠ” í•„í„° ìœ í˜•
        
        # í•„í„°ë§ ì¡°ê±´ì— ë§ì§€ ì•Šìœ¼ë©´ ì œì™¸
        if pattern_type_filter and not is_match: return None
        
        # 8. ê²°ê³¼ ì •ë¦¬ ë° ë°˜í™˜
        if analysis_results or fundamentals or headlines:
            # None ë˜ëŠ” NaN ê°’ ì •ë¦¬ (JSON ì§ë ¬í™” ì˜¤ë¥˜ ë°©ì§€)
            fundamentals_clean = {k: v for k, v in fundamentals.items() if v is not None and not (isinstance(v, (float, np.float64)) and np.isnan(v))}
            analysis_clean = {k: v for k, v in analysis_results.items() if v is not None and not (isinstance(v, (float, np.float64)) and np.isnan(v))}
            
            return {
                "ticker": code,
                "name": name,
                "technical_conditions": analysis_clean,
                "fundamentals": fundamentals_clean,
                "recent_news_headlines": headlines
            }
        return None
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡ í›„ None ë°˜í™˜ (ë³‘ë ¬ ì²˜ë¦¬ì˜ ì•ˆì •ì„± í™•ë³´)
        logging.error(f"[ERROR] {code} {name} ë¶„ì„ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}") 
        return None

def run_analysis(workers, ma_periods_str, analyze_patterns, exclude_negatives, pattern_type_filter):
    """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì´ìš©í•´ ì „ì²´ ì¢…ëª© ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  ì§„í–‰ë¥ ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    start_time = time.time()
    periods = [int(p.strip()) for p in ma_periods_str.split(',') if p.strip().isdigit()]
    
    # íŒ¨í„´ í•„í„°ê°€ ì„¤ì •ë˜ë©´ íŒ¨í„´ ë¶„ì„ì„ ê°•ì œë¡œ í™œì„±í™”í•©ë‹ˆë‹¤.
    if pattern_type_filter and pattern_type_filter not in ['ma', 'regime'] and not pattern_type_filter.startswith('regime:'): 
        analyze_patterns = True 
    
    # MA í¬ë¡œìŠ¤ ì²´í¬ ë° íŒ¨í„´ ë¶„ì„ì„ ìœ„í•´ 50ì¼, 200ì¼ì€ ê°•ì œë¡œ í¬í•¨
    if 50 not in periods: periods.append(50) 
    if 200 not in periods: periods.append(200)

    items = load_listing()
    initial_item_count = len(items)
    results = []
    
    logging.warning(f"ë¶„ì„ ì‹œì‘: ì´ {initial_item_count} ì¢…ëª©, ìµœëŒ€ ì›Œì»¤ {workers}ê°œ ì‚¬ìš©. í•„í„°: {pattern_type_filter or 'None'}")

    processed_count = 0
    
    with ThreadPoolExecutor(max_workers=workers) as executor:
        future_to_item = {
            executor.submit(analyze_symbol, item, periods, analyze_patterns, exclude_negatives, pattern_type_filter): item
            for item in items
        }
        
        for future in as_completed(future_to_item):
            # ì›¹ ì—°ë™ì„ ìœ„í•œ ì‹¤ì‹œê°„ ì§„í–‰ë¥  JSON ì¶œë ¥ (í•„ìˆ˜)
            processed_count += 1
            progress_percent = round((processed_count / initial_item_count) * 100, 2)
            
            sys.stdout.write(json.dumps({
                "mode": "progress",
                "total_symbols": initial_item_count,
                "processed_symbols": processed_count,
                "progress_percent": progress_percent
            }, ensure_ascii=False) + "\n")
            sys.stdout.flush()
            
            try:
                r = future.result()
                if r: results.append(r)
            except Exception as e:
                code = future_to_item[future].get("Code") or future_to_item[future].get("code")
                name = future_to_item[future].get("Name") or future_to_item[future].get("name")
                logging.error(f"[ERROR] {code} {name} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
    
    end_time = time.time()
    
    data_check = {
        "listing_file_exists": LISTING_FILE.exists(),
        "dart_available": DART_AVAILABLE,
        "total_symbols_loaded": initial_item_count,
        "time_taken_sec": round(end_time - start_time, 2),
    }

    logging.warning(f"ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì¢…ëª© í•„í„°ë§ ë¨. ì´ ì†Œìš” ì‹œê°„: {data_check['time_taken_sec']}ì´ˆ")
    # ìµœì¢… ê²°ê³¼ ì¶œë ¥ ë° ì •ìƒ ì¢…ë£Œ (status_code=0)
    safe_print_json({
        "results": results, 
        "mode": "analyze_result",
        "filter": pattern_type_filter or 'ma_only',
        "data_check": data_check
    }, status_code=0)

def generate_chart(symbol, ma_periods_str):
    """ë‹¨ì¼ ì¢…ëª©ì˜ ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  Base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    code = symbol
    name = get_stock_name(code)
    periods = [int(p.strip()) for p in ma_periods_str.split(',') if p.strip().isdigit()]
    path = DATA_DIR / f"{code}.parquet"
    
    if not path.exists():
        safe_print_json({"error": f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {path}"}, status_code=1)
        return
    
    try:
        df = pd.read_parquet(path)
        if df.empty:
            safe_print_json({"error": "ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."}, status_code=1)
            return
            
        # ìµœê·¼ 250ì¼ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ìƒì„±
        df_for_chart = df.iloc[-250:].copy() 
        df_for_chart = calculate_advanced_features(df_for_chart)
        
        if df_for_chart.empty:
            safe_print_json({"error": "íŠ¹ì§• ê³„ì‚° í›„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì°¨íŠ¸ ìƒì„± ë¶ˆê°€."}, status_code=1)
            return

        ma_lines = []
        for p in periods:
            ma_col_name = f'SMA_{p}' if p in [20, 50, 200] else f'ma{p}'
            # ì´ë¯¸ ê³„ì‚°ëœ SMAëŠ” ì¬ì‚¬ìš©í•˜ê±°ë‚˜, ëª…ì‹œëœ ê¸°ê°„ì´ ì•„ë‹ˆë©´ rolling mean ê³„ì‚°
            if ma_col_name not in df_for_chart.columns:
                df_for_chart[ma_col_name] = df_for_chart['Close'].rolling(window=p, min_periods=1).mean()

            if ma_col_name in df_for_chart.columns and not df_for_chart[ma_col_name].isnull().all():
                color_map = {5: 'red', 20: 'orange', 50: 'purple', 200: 'blue'}
                ma_lines.append(mpf.make_addplot(df_for_chart[ma_col_name], panel=0, type='line', width=1.0, 
                                                 color=color_map.get(p, 'green'), secondary_y=False))
        
        # MACDë¥¼ ë³„ë„ íŒ¨ë„ì— ì¶”ê°€ (panel=2)
        macd_plot = mpf.make_addplot(df_for_chart['MACD'], panel=2, type='line', secondary_y=False, color='red', width=1.0, title='MACD')
        
        # mpf.make_marketcolors ì¸ì ê°œì„ : Deprecation ê²½ê³ ë¥¼ í”¼í•˜ê³  ìµœì‹  ê·œê²© ë”°ë¦„
        mc = mpf.make_marketcolors(up='red', down='blue', 
                                   edge='black', 
                                   wick='black', 
                                   volume='gray', 
                                   ohlc='i') # ohlc='i'ëŠ” Inverted (ìƒ‰ìƒì´ ì±„ì›Œì§)
        
        s = mpf.make_mpf_style(marketcolors=mc, gridcolor='gray', figcolor='white', y_on_right=False, 
                               rc={'font.family': MPLFINANCE_FONT}, 
                               base_mpf_style='yahoo') # ê¸°ë³¸ ìŠ¤íƒ€ì¼ì„ yahooë¡œ ì„¤ì •í•˜ì—¬ ì•ˆì •ì„± í™•ë³´
        
        addplots = ma_lines + [macd_plot]
        
        # ì°¨íŠ¸ ìƒì„±
        fig, axes = mpf.plot(df_for_chart, type='candle', style=s, 
                             title=f"{name} ({code}) Technical Analysis Chart", 
                             ylabel='Price (KRW)', ylabel_lower='Volume', volume=True, 
                             addplot=addplots, figscale=1.5, returnfig=True, 
                             tight_layout=True)
        
        # ì°¨íŠ¸ë¥¼ Base64ë¡œ ì¸ì½”ë”©
        buf = io.BytesIO()
        fig.savefig(buf, format='png', bbox_inches='tight')
        plt.close(fig) # ë©”ëª¨ë¦¬ í•´ì œ
        image_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')
        
        # ì°¨íŠ¸ ê²°ê³¼ ì¶œë ¥ ë° ì •ìƒ ì¢…ë£Œ (status_code=0)
        safe_print_json({"ticker": code, "name": name, "chart_image_base64": image_base64, "mode": "chart"}, status_code=0)
        
    except Exception as e:
        logging.error(f"[ERROR] ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨ ({code} {name}): {e}\n{traceback.format_exc()}")
        safe_print_json({"error": f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}"}, status_code=1)

def main():
    """ìŠ¤í¬ë¦½íŠ¸ì˜ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    parser = argparse.ArgumentParser(description="ì£¼ì‹ ë°ì´í„° ë¶„ì„ ë° ì°¨íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--mode", type=str, required=True, choices=['analyze', 'chart'], help="ì‹¤í–‰ ëª¨ë“œ ì„ íƒ: 'analyze' ë˜ëŠ” 'chart'")
    parser.add_argument("--workers", type=int, default=os.cpu_count() * 2, help="ë¶„ì„ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  ìµœëŒ€ ìŠ¤ë ˆë“œ ìˆ˜")
    parser.add_argument("--ma_periods", type=str, default="20,50,200", help="ì´ë™ í‰ê· ì„  ê¸°ê°„ ì§€ì • (ì‰¼í‘œë¡œ êµ¬ë¶„)")
    parser.add_argument("--symbol", type=str, help="ì°¨íŠ¸ ëª¨ë“œì—ì„œ ì‚¬ìš©í•  ì¢…ëª© ì½”ë“œ")
    parser.add_argument("--analyze_patterns", action="store_true", help="íŒ¨í„´ ê°ì§€ í™œì„±í™”")
    parser.add_argument("--pattern_type", type=str, 
                        choices=['ma', 'double_bottom', 'triple_bottom', 'cup_and_handle', 'goldencross', 'regime:0', 'regime:1', 'regime:2', 'regime:3'], 
                        help="í•„í„°ë§í•  íŒ¨í„´ ì¢…ë¥˜ (ì˜ˆ: 'regime:0' ë˜ëŠ” 'goldencross')") 
    parser.add_argument("--exclude_negatives", action="store_true", help="ì•…ì¬ì„± ì¢…ëª© ì œì™¸")
    args = parser.parse_args()
    
    try:
        if args.mode == 'analyze':
            run_analysis(args.workers, args.ma_periods, args.analyze_patterns, args.exclude_negatives, args.pattern_type) 
        elif args.mode == 'chart':
            if not args.symbol: 
                # ì¸ìˆ˜ ëˆ„ë½ ì‹œ ì¹˜ëª…ì  ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¦‰ì‹œ ì¢…ë£Œ
                safe_print_json({
                    "error": "CRITICAL_ERROR", 
                    "reason": "ì°¨íŠ¸ ëª¨ë“œì—ëŠ” --symbol ì¸ìˆ˜ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.",
                    "mode": "argument_check"
                })
            generate_chart(args.symbol, args.ma_periods) 
    except Exception as e:
        error_msg = f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}"
        # ê¸°íƒ€ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ
        safe_print_json({
            "error": "CRITICAL_ERROR", 
            "reason": error_msg,
            "traceback": traceback.format_exc(),
            "mode": "runtime_error"
        })
    # ëª¨ë“  ì •ìƒ ì‹¤í–‰ ê²½ë¡œëŠ” run_analysis ë˜ëŠ” generate_chart ë‚´ë¶€ì˜ safe_print_json(status_code=0)ì—ì„œ ì²˜ë¦¬ë¨
    sys.exit(0)

if __file__ != '<stdin>' and __name__ == "__main__":
    main()